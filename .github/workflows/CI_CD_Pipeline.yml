
name: CI/CD Pipeline


on:
  push:
    branches:
      - main

jobs:
  build_and_test:
    runs-on: ubuntu-latest

    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      PORT_PROD: ${{ vars.PORT_PROD }}
      PORT_DEV: ${{ vars.PORT_DEV }}
      SECRET_KEY: ${{ secrets.SECRET_KEY }}
      ALGORITHM: ${{ secrets.ALGORITHM }}
      ACCESS_TOKEN_EXPIRES_MINUTES: ${{ vars.ACCESS_TOKEN_EXPIRES_MINUTES }}
      AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_BUCKET_NAME_DEV: ${{ vars.AWS_BUCKET_NAME_DEV }}
      AWS_REGION_TEST: ${{ vars.AWS_REGION_TEST }}
      PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
      PINECONE_INDEX: ${{ vars.PINECONE_INDEX }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      PINECONE_VECTOR_DIMENSION: ${{ vars.PINECONE_VECTOR_DIMENSION }}
      RDS_POSTGRESQL_PASSWORD: ${{ vars.RDS_POSTGRESQL_PASSWORD }}
      WORKFLOW_IMAGE_NAME:  ${{ vars.WORKFLOW_IMAGE_NAME }}
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
        export PATH="$HOME/.local/bin:$PATH"

    - name: Export dependencies 
      run: |
        poetry export -f requirements.txt --output requirements.txt --without-hashes

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run tests
      run: |
        pytest

  build_and_push_image:
    runs-on: ubuntu-latest
    needs: build_and_test
    if: success()

    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      PORT_PROD: ${{ vars.PORT_PROD }}
      PORT_DEV: ${{ vars.PORT_DEV }}
      SECRET_KEY: ${{ secrets.SECRET_KEY }}
      ALGORITHM: ${{ secrets.ALGORITHM }}
      ACCESS_TOKEN_EXPIRES_MINUTES: ${{ vars.ACCESS_TOKEN_EXPIRES_MINUTES }}
      AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_BUCKET_NAME_DEV: ${{ vars.AWS_BUCKET_NAME_DEV }}
      AWS_REGION_TEST: ${{ vars.AWS_REGION_TEST }}
      PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
      PINECONE_INDEX: ${{ vars.PINECONE_INDEX }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      PINECONE_VECTOR_DIMENSION: ${{ vars.PINECONE_VECTOR_DIMENSION }}
      RDS_POSTGRESQL_PASSWORD: ${{ vars.RDS_POSTGRESQL_PASSWORD }}
      WORKFLOW_IMAGE_NAME:  ${{ vars.WORKFLOW_IMAGE_NAME }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ vars.AWS_REGION_TEST }}

    - name: Login to Amazon ECR
      id: ecr-login
      run: |
        aws ecr get-login-password --region ${{ vars.AWS_REGION_TEST }} | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}

    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
        export PATH="$HOME/.local/bin:$PATH"

    - name: Export dependencies 
      run: |
        poetry export -f requirements.txt --output requirements.txt --without-hashes

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Install Docker Compose
      run: |
        sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
        
    - name: Build, tag, and push Docker image
      run: |
        docker-compose -f docker-compose.ci.yml build
        docker tag ${{vars.WORKFLOW_IMAGE_NAME}}:latest ${{ secrets.ECR_REGISTRY }}:latest
        docker push ${{ secrets.ECR_REGISTRY }}:latest
        
  pull_image_and_deploy_in_ec2_instance:
    runs-on: ubuntu-latest
    needs: build_and_push_image
    if: success()

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Create PEM file
        run: echo "${{ secrets.EC2_PEM_SECRET }}" > pdf-query-pro-backend-key-pair.pem

      - name: Set permissions for PEM file
        run: chmod 400 pdf-query-pro-backend-key-pair.pem

      - name: Connect to EC2 and run commands
        run: |
          ssh -o StrictHostKeyChecking=no -i "pdf-query-pro-backend-key-pair.pem" ec2-user@ec2-47-128-237-25.ap-southeast-1.compute.amazonaws.com << 'EOF'
            ls -ltr
            
            aws ecr get-login-password --region ${{vars.AWS_REGION_TEST}} | docker login --username AWS --password-stdin ${{secrets.ECR_REGISTRY}}

            docker-compose down

            rm -f docker-compose.yml

            docker rmi ${{ secrets.ECR_REGISTRY }}:latest
            
            # Create a new Docker Compose file using echo
            echo "version: '3.8'" > docker-compose.yml
            echo "" >> docker-compose.yml
            echo "services:" >> docker-compose.yml
            echo "  pdf-query-pro-backend:" >> docker-compose.yml
            echo "    container_name: pdf_query_pro_backend_container" >> docker-compose.yml
            echo "    image: ${{ secrets.ECR_REGISTRY }}:latest" >> docker-compose.yml
            echo "    pull_policy: always" >> docker-compose.yml
            echo "    ports:" >> docker-compose.yml
            echo "      - \"80:8000\"" >> docker-compose.yml
            echo "    environment:" >> docker-compose.yml
            echo "      - DATABASE_URL=${{ secrets.DATABASE_URL }}" >> docker-compose.yml
            echo "      - PORT_PROD=${{ vars.PORT_PROD }}" >> docker-compose.yml
            echo "      - PORT_DEV=${{ vars.PORT_DEV }}" >> docker-compose.yml
            echo "      - SECRET_KEY=${{ secrets.SECRET_KEY }}" >> docker-compose.yml
            echo "      - ALGORITHM=${{ secrets.ALGORITHM }}" >> docker-compose.yml
            echo "      - ACCESS_TOKEN_EXPIRES_MINUTES=${{ vars.ACCESS_TOKEN_EXPIRES_MINUTES }}" >> docker-compose.yml
            echo "      - AWS_ACCESS_KEY=${{ secrets.AWS_ACCESS_KEY }}" >> docker-compose.yml
            echo "      - AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> docker-compose.yml
            echo "      - AWS_BUCKET_NAME_DEV=${{ vars.AWS_BUCKET_NAME_DEV }}" >> docker-compose.yml
            echo "      - AWS_REGION_TEST=${{ vars.AWS_REGION_TEST }}" >> docker-compose.yml
            echo "      - PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }}" >> docker-compose.yml
            echo "      - PINECONE_INDEX=${{ vars.PINECONE_INDEX }}" >> docker-compose.yml
            echo "      - OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> docker-compose.yml
            echo "      - PINECONE_VECTOR_DIMENSION=${{ vars.PINECONE_VECTOR_DIMENSION }}" >> docker-compose.yml
            echo "      - RDS_POSTGRESQL_PASSWORD=${{ vars.RDS_POSTGRESQL_PASSWORD }}" >> docker-compose.yml

            
            docker-compose up -d

            sleep 20

            docker ps

            # Check if container is running
            if [ $(docker ps -q -f name=pdf_query_pro_backend_container | wc -l) -eq 0 ]; then
              echo "Container is not running"
              exit 1
            fi

            docker logs pdf_query_pro_backend_container

            # Add more commands as needed
          EOF
